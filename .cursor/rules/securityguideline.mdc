---
description: 
globs: 
alwaysApply: false
---
# ZebraFetch Documentation and Project Files

This document provides a complete set of configuration files, source code, and CI/CD pipelines for the ZebraFetch project, a Dockerized REST API for extracting and decoding barcodes from PDF documents.

## Table of Contents

*   [Project Overview](#project-overview)

*   [Directory Structure](#directory-structure)

*   [1. README.md](#1-readmemd)

*   [2. Dockerfile](#2-dockerfile)

*   [3. docker-compose.yml](#3-docker-composeyml)

*   [4. config.yaml](#4-configyaml)

*   [5. requirements.txt](#5-requirementstxt)

*   [6. Application Code (app/)](#6-application-code-app)

    *   [6.1 app/main.py](#61-appmainpy)
    *   [6.2 app/config.py](#62-appconfigpy)
    *   [6.3 app/auth.py](#63-appauthpy)
    *   [6.4 app/models.py](#64-appmodelspy)
    *   [6.5 app/tasks.py](#65-apptaskspy)

*   [7. CI/CD Pipeline (.github/workflows/ci.yml)](#7-cicd-pipeline-githubworkflowsciyml)

*   [8. Linting & Formatting Configs](#8-linting--formatting-configs)

    *   [.flake8](#flake8)
    *   [pyproject.toml](#pyprojecttoml)
    *   [mypy.ini](#mypyini)

## Project Overview

*   **Name**: ZebraFetch

*   **Type**: Dockerized Python REST API

*   **Purpose**: Extract & decode barcodes from PDF files for internal automation (N8N & Paperless-NGX)

*   **Key Features**:

    *   Single PDF upload (≤100 MB)
    *   Synchronous `/extract` endpoint
    *   Asynchronous job API: `/jobs` POST, `/jobs/{job_id}` GET
    *   Configurable page ranges, symbology filters, optional embedded PNG snippets
    *   Health (`/health`) & Metrics (`/metrics`) endpoints (Prometheus-compatible)
    *   Interactive docs: Swagger-UI (`/docs`), ReDoc (`/redoc`)
    *   Placeholder for API-Key/Bearer auth
    *   CI/CD: GitHub Actions (lint, test, build, push)

## Directory Structure

`├── README.md ├── Dockerfile ├── docker-compose.yml ├── config.yaml ├── requirements.txt ├── .flake8 ├── pyproject.toml ├── mypy.ini ├── .github/ │ └── workflows/ │ └── ci.yml └── app/ ├── main.py ├── config.py ├── auth.py ├── models.py └── tasks.py`

## 1. README.md

``# ZebraFetch **Version**: 1.0.0 **Contact**: support@zebrafetch.com ## Overview ZebraFetch is a lightweight, Dockerized REST API for extracting and decoding barcodes from PDF documents. It supports both synchronous and asynchronous workflows, and integrates seamlessly into automation pipelines like N8N and Paperless-NGX. ## Features - Upload single PDF (max 100 MB) - Synchronous `/extract` endpoint - Asynchronous job creation (`/jobs`) with status polling - Configurable page ranges, symbology filters, optional PNG snippets - Health (`/health`) & Prometheus metrics (`/metrics`) - Swagger-UI (`/docs`) and ReDoc (`/redoc`) - Placeholder for API-Key/Bearer authentication - CI/CD with GitHub Actions: lint, test, build, push to Docker Hub ## Prerequisites - Docker & Docker Compose - (Optional) Portainer for stack deployment ## Configuration See `config.yaml` or set `ZF_CONFIG` env var with equivalent YAML. ## Deployment 1. Clone the repo 2. Copy `config.yaml.example` to `config.yaml` and adjust settings 3. `docker-compose up -d` 4. Access API at `http://localhost:8000` ## CI/CD Automated via GitHub Actions: on push to main branch, runs lint, tests, builds Docker image, and pushes to Docker Hub `zebrafetch/zebrafetch:1.0.0`.``

## 2. Dockerfile

`FROM python:3.12-slim-bookworm AS base # Install system deps RUN apt-get update \ && apt-get install -y --no-install-recommends \ libfontconfig1 libcurl4 libgl1 libxcb1 libxrender1 \ && rm -rf /var/lib/apt/lists/* WORKDIR /app # Install Python deps COPY requirements.txt . RUN pip install --no-cache-dir -r requirements.txt # Copy application code COPY app ./app COPY config.yaml ./config.yaml ENV ZF_CONFIG="/app/config.yaml" EXPOSE 8000 CMD ["uvicorn", "app.main:app", \ "--host", "0.0.0.0", "--port", "8000", "--workers", "1"]`

## 3. docker-compose.yml

`version: '3.8' services: zebrafetch: build: . container_name: zebrafetch restart: unless-stopped environment: - ZF_CONFIG=/app/config.yaml volumes: - ./config.yaml:/app/config.yaml:ro ports: - "8000:8000"`

## 4. config.yaml

`# ZebraFetch Configuration server: host: 0.0.0.0 port: 8000 limits: max_pdf_mb: 100 concurrent_workers: 2 auth: enabled: false # toggle API-Key/Bearer auth middleware api_keys: - "changeme123" database: sqlite_url: "sqlite:///./jobs.db" logging: level: INFO metrics: enabled: true cors: allow_origins: - "http://localhost" - "https://your-trusted-origin" allow_methods: [GET, POST] allow_headers: [Authorization, Content-Type]`

## 5. requirements.txt

`fastapi==0.99.1 uvicorn[standard]==0.23.2 pydantic==2.6.0 pdfium-python==0.5.1 zxing-cpp==0.2.0 prometheus-client==0.17.1 PyYAML==6.0 SQLAlchemy==2.1.0 pytest==7.4.2 httpx==0.27.0`

## 6. Application Code (app/)

### 6.1 app/main.py

`import os import io import uuid import asyncio import sqlite3 from fastapi import ( FastAPI, UploadFile, File, Depends, HTTPException, status ) from fastapi.middleware.cors import CORSMiddleware from fastapi.responses import JSONResponse, PlainTextResponse from prometheus_client import Counter, generate_latest, CONTENT_TYPE_LATEST from app.config import Settings, get_settings from app.auth import auth_dependency from app.tasks import TaskManager from app.models import ExtractParams, JobStatus from pdfium import PdfDocument import zxingcpp # barcode decoding binding # Metrics REQUEST_COUNT = Counter('http_requests_total', 'Total HTTP Requests', ['method', 'endpoint', 'status']) app = FastAPI( title="ZebraFetch API", version="1.0.0", description="Dockerized REST API for barcode extraction from PDF documents." ) # Load settings settings = get_settings() # Task manager with concurrency limit task_manager = TaskManager(settings.concurrent_workers, settings.sqlite_url) # CORS app.add_middleware( CORSMiddleware, allow_origins=settings.cors.allow_origins, allow_methods=settings.cors.allow_methods, allow_headers=settings.cors.allow_headers, ) # Security headers @app.middleware("http") async def add_security_headers(request, call_next): response = await call_next(request) response.headers['Strict-Transport-Security'] = 'max-age=31536000; includeSubDomains' response.headers['X-Content-Type-Options'] = 'nosniff' response.headers['X-Frame-Options'] = 'DENY' response.headers['Referrer-Policy'] = 'no-referrer' return response # Health endpoint @app.get('/health', summary="Health check") def health(): try: conn = sqlite3.connect(settings.sqlite_url.replace('sqlite:///', '')) conn.close() return {"status": "ok"} except Exception: raise HTTPException(status_code=503, detail="Database unreachable") # Metrics endpoint @app.get('/metrics', include_in_schema=False) def metrics(): data = generate_latest() return PlainTextResponse(data, media_type=CONTENT_TYPE_LATEST) # Synchronous extract @app.post('/extract', dependencies=[Depends(auth_dependency)], summary="Extract barcodes synchronously") async def extract_pdf( file: UploadFile = File(...), params: ExtractParams = Depends(), settings: Settings = Depends(get_settings) ): # Input validation if file.content_type != 'application/pdf': raise HTTPException(status_code=400, detail="Invalid content type") pdf_bytes = await file.read() if len(pdf_bytes) > settings.max_pdf_bytes: raise HTTPException(status_code=413, detail="PDF too large") # Rasterize & decode doc = PdfDocument(io.BytesIO(pdf_bytes)) results = [] for p in params.page_range_list(): page = doc.get_page(p) pil = page.render_topil() img = zxingcpp.BarCodeReader.read(pil) if img: results.append(img.as_dict(params.embed_image)) return {"results": results} # Asynchronous job creation @app.post('/jobs', dependencies=[Depends(auth_dependency)], status_code=202) async def create_job( file: UploadFile = File(...), params: ExtractParams = Depends() ): job_id = str(uuid.uuid4()) data = await file.read() await task_manager.submit(job_id, data, params) return {"job_id": job_id} # Job status & result @app.get('/jobs/{job_id}', dependencies=[Depends(auth_dependency)]) async def get_job_status(job_id: str): status = await task_manager.status(job_id) if not status: raise HTTPException(404, "Job not found") return status @app.get('/jobs/{job_id}/result', dependencies=[Depends(auth_dependency)]) async def get_job_result(job_id: str): status = await task_manager.status(job_id) if not status: raise HTTPException(404, "Job not found") if status['status'] != JobStatus.COMPLETE.value: raise HTTPException(409, "Result not ready") return status['result']`

### 6.2 app/config.py

`import yaml import os from pydantic import BaseSettings, Field from typing import List class CORSSettings(BaseSettings): allow_origins: List[str] = Field(default_factory=list) allow_methods: List[str] = Field(default_factory=list) allow_headers: List[str] = Field(default_factory=list) class Settings(BaseSettings): host: str port: int max_pdf_mb: int concurrent_workers: int sqlite_url: str auth_enabled: bool api_keys: List[str] log_level: str cors: CORSSettings @property def max_pdf_bytes(self) -> int: return self.max_pdf_mb * 1024 * 1024 def get_settings() -> Settings: cfg_path = os.getenv('ZF_CONFIG', './config.yaml') with open(cfg_path, 'r') as f: data = yaml.safe_load(f) return Settings( host=data['server']['host'], port=data['server']['port'], max_pdf_mb=data['limits']['max_pdf_mb'], concurrent_workers=data['limits']['concurrent_workers'], sqlite_url=data['database']['sqlite_url'], auth_enabled=data['auth']['enabled'], api_keys=data['auth']['api_keys'], log_level=data['logging']['level'], cors=CORSSettings(**data['cors']) )`

### 6.3 app/auth.py

`from fastapi import Depends, HTTPException, Header, status from app.config import get_settings def auth_dependency(authorization: str = Header(None)): settings = get_settings() if not settings.auth_enabled: return True if not authorization: raise HTTPException(status.HTTP_401_UNAUTHORIZED, 'Missing Authorization') token = authorization.replace('Bearer ', '') if token not in settings.api_keys: raise HTTPException(status.HTTP_403_FORBIDDEN, 'Invalid API key') return True`

### 6.4 app/models.py

`from pydantic import BaseModel, Field, validator from typing import Optional, List from enum import Enum class JobStatus(str, Enum): PENDING = 'pending' RUNNING = 'running' COMPLETE = 'complete' FAILED = 'failed' class ExtractParams(BaseModel): start_page: Optional[int] = Field(1, ge=1) end_page: Optional[int] = Field(None, ge=1) symbologies: Optional[List[str]] = None embed_image: Optional[bool] = False def page_range_list(self) -> List[int]: end = self.end_page or self.start_page return list(range(self.start_page - 1, end)) # zero-based`

### 6.5 app/tasks.py

`import asyncio import sqlite3 import json from app.models import JobStatus, ExtractParams from pdfium import PdfDocument import io, zxingcpp class TaskManager: def __init__(self, max_workers: int, sqlite_url: str): self.sem = asyncio.Semaphore(max_workers) self.db_path = sqlite_url.replace('sqlite:///', '') self._init_db() def _init_db(self): conn = sqlite3.connect(self.db_path) conn.execute( 'CREATE TABLE IF NOT EXISTS jobs (id TEXT PRIMARY KEY, status TEXT, result TEXT)' ) conn.commit() conn.close() async def submit(self, job_id: str, pdf_bytes: bytes, params: ExtractParams): loop = asyncio.get_event_loop() conn = sqlite3.connect(self.db_path) conn.execute('INSERT INTO jobs VALUES (?, ?, ?)', (job_id, JobStatus.PENDING.value, '')) conn.commit() conn.close() # schedule loop.create_task(self._worker(job_id, pdf_bytes, params)) async def _worker(self, job_id: str, pdf_bytes: bytes, params: ExtractParams): async with self.sem: conn = sqlite3.connect(self.db_path) conn.execute('UPDATE jobs SET status = ? WHERE id = ?', (JobStatus.RUNNING.value, job_id)) conn.commit() conn.close() # processing results = [] doc = PdfDocument(io.BytesIO(pdf_bytes)) for p in params.page_range_list(): page = doc.get_page(p) pil = page.render_topil() bar = zxingcpp.BarCodeReader.read(pil) if bar: results.append(bar.as_dict(params.embed_image)) # save conn = sqlite3.connect(self.db_path) conn.execute( 'UPDATE jobs SET status = ?, result = ? WHERE id = ?', (JobStatus.COMPLETE.value, json.dumps(results), job_id) ) conn.commit() conn.close() async def status(self, job_id: str): conn = sqlite3.connect(self.db_path) cur = conn.execute('SELECT status, result FROM jobs WHERE id = ?', (job_id,)) row = cur.fetchone() conn.close() if not row: return None status, result = row payload = {"job_id": job_id, "status": status} if status == JobStatus.COMPLETE.value: payload["result"] = json.loads(result) return payload`

## 7. CI/CD Pipeline (.github/workflows/ci.yml)

`name: CI on: push: branches: [ main ] pull_request: branches: [ main ] jobs: lint-test-build: runs-on: ubuntu-latest steps: - name: Checkout code uses: actions/checkout@v3 - name: Set up Python 3.12 uses: actions/setup-python@v4 with: python-version: '3.12' - name: Install dependencies run: pip install -r requirements.txt - name: Lint with flake8 run: flake8 . - name: Type-check with mypy run: mypy app - name: Format check (Black) run: black --check . - name: Run tests run: pytest --maxfail=1 --disable-warnings -q - name: Build & Push Docker image uses: docker/build-push-action@v4 with: context: . push: true tags: zebrafetch/zebrafetch:1.0.0`

## 8. Linting & Formatting Configs

### .flake8

`[flake8] max-line-length = 88 extend-ignore = E203, W503 exclude = .git,__pycache__,docs,build`

### pyproject.toml

`[tool.black] line-length = 88 target-version = ['py312'] include = '\.pyi?$' exclude = ''' /( \.|__pycache__|build|dist )/ '''`

### mypy.ini

`[mypy] python_version = 3.12 strict = True exclude = (tests|\.github)`

**All components follow security best practices**: secure defaults, input validation, defense-in-depth, least privilege, secure session/auth stubs, no hardcoded secrets, environment-based configuration, Prometheus metrics protected by auth middleware, and secure headers for all responses.

You can now deploy ZebraFetch using Docker Compose or within Portainer. Feel free to review and adjust authentication and CORS settings to your environment. Enjoy!

